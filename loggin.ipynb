{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loggin\n",
    "\n",
    "## 使用cookie\n",
    "\n",
    "1. 手动从chrome中拷贝cookie\n",
    "\n",
    "在登录页或者主页，先打开chrome的network，然后再进行登录或者刷新页面，最好在preserve log前面打钩，然后找到network中登录页或者主页的请求，左键点击，就能看到headers，在request header中能找到cookie信息。\n",
    "\n",
    "另外，参考[dataabc/weiboSpider](https://github.com/arfu2016/weiboSpider)\n",
    "\n",
    "2. 用python从chrome自带嵌入式数据库中读取cookie\n",
    "\n",
    "[arfu2016/browser_cookie3](https://github.com/arfu2016/browser_cookie3)\n",
    "\n",
    "[How to get cookies from web-browser with Python?](https://stackoverflow.com/questions/8812420/how-to-get-cookies-from-web-browser-with-python#)\n",
    "\n",
    "简单讲，chrome是把各个网站的cookie放入sqlite数据库中，但是做了加密处理。因为chrome核心的源代码是公开的，所以可以查到加密算法是怎样的，用python把cookie从数据库中取出来，然后用加密算法的逆算法进行处理即可（chrome也是这么做的，只是不是用python）\n",
    "\n",
    "3. 用scrapy获取不断变化的cookie\n",
    "\n",
    "## 手动Chrome识别验证码，并与python服务器交互，建立websocket连接\n",
    "\n",
    "客户端浏览器发出请求，与python服务器建立websocket连接，同时请求python服务器向外部网站发出请求，外部网站的回复再由python服务器传给客户端浏览器，展示验证码，解出来的结果通过python服务器传给外部网站，外部网站返回的cookie等信息可用于python服务器爬虫。如果外部网站在某个时候再次发回验证码，就再由python服务器发给客户端，并发出警报声（就好像自动抢票的插件一样），人工解出来以后返回。\n",
    "\n",
    "## python自动获取验证码图片，传给相关服务器，并拿到识别结果，建立http连接\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 尝试爬取微博"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "class NetTour:\n",
    "    your_cookie = ''\n",
    "    cookie = {\"Cookie\": your_cookie}  # 将your cookie替换成自己的cookie\n",
    "\n",
    "    def __init__(self, user_id):\n",
    "        self.user_id = user_id\n",
    "        self.username = ''\n",
    "        # self.dryscrape_session = dryscrape.Session()\n",
    "\n",
    "    def get_username_static_cookie(self):\n",
    "        try:\n",
    "            url = \"https://weibo.com/{}?is_all=1\".format(self.user_id)\n",
    "\n",
    "            user_agent = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.87 Safari/537.36'\n",
    "            default_request_headers = {\n",
    "                'Connection': 'Keep-Alive',\n",
    "                'Upgrade-Insecure-Requests': '1', \n",
    "                'User-Agent': user_agent,\n",
    "                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8', \n",
    "                'Accept-Encoding': 'gzip, deflate, br', \n",
    "                'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8'\n",
    "            }\n",
    "            html = requests.get(url, cookies=self.cookie,\n",
    "                                headers=default_request_headers).content\n",
    "            print('Successfully get html.')\n",
    "            return html\n",
    "        except Exception as e:\n",
    "            print(\"Error: \", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try180707a = NetTour('210009776')\n",
    "\n",
    "bytes_html = try180707a.get_username_static_cookie()\n",
    "\n",
    "string_html = bytes_html.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Part of html', string_html[0:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 尝试爬取雪球"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import logging\n",
    "\n",
    "class NetTour:\n",
    "\n",
    "    def __init__(self, user_id, your_cookie):\n",
    "        logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',\n",
    "                    level=logging.INFO)\n",
    "        self.cookie = {\"Cookie\": your_cookie}\n",
    "        self.stock_id = user_id\n",
    "        self.username = ''\n",
    "        # self.dryscrape_session = dryscrape.Session()\n",
    "\n",
    "    def get_username_static_cookie(self, web_url):\n",
    "        try:\n",
    "            url = web_url.format(self.stock_id)\n",
    "\n",
    "            user_agent = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.87 Safari/537.36'\n",
    "            default_request_headers = {\n",
    "                'Connection': 'Keep-Alive',\n",
    "                'Upgrade-Insecure-Requests': '1', \n",
    "                'User-Agent': user_agent,\n",
    "                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8', \n",
    "                'Accept-Encoding': 'gzip, deflate, br', \n",
    "                'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',\n",
    "                'Cache-Control': 'max-age=0'\n",
    "            }\n",
    "            html = requests.get(url, cookies=self.cookie,\n",
    "                                headers=default_request_headers).content\n",
    "            logging.info('Successfully get html.')\n",
    "            return html\n",
    "        except Exception as e:\n",
    "            logging.exception('Exception occurs.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_cookie = ''\n",
    "\n",
    "web_url = \"https://xueqiu.com/S/{}/FHPS\"\n",
    "\n",
    "try180708a = NetTour('SZ300244', my_cookie)\n",
    "\n",
    "bytes_html = try180708a.get_username_static_cookie(web_url)\n",
    "\n",
    "string_html = bytes_html.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "web_url = 'https://xueqiu.com/S/{}'\n",
    "bytes_html = try180708a.get_username_static_cookie(web_url)\n",
    "string_html = bytes_html.decode('utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
